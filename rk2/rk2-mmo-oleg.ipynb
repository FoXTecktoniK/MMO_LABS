{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рубежный контроль №2\n",
    "## Румянцев Олег \n",
    "### Группа ИУ5-22М\n",
    "**Тема: Методы обработки текстов.**\n",
    "\n",
    "**Решение задачи классификации текстов.**\n",
    "\n",
    "Необходимо решить задачу классификации текстов на основе любого выбранного Вами датасета. Классификация может быть бинарной или многоклассовой. Целевой признак из выбранного Вами датасета может иметь любой физический смысл, примером является задача анализа тональности текста.\n",
    "\n",
    "Необходимо сформировать два варианта векторизации признаков - на основе CountVectorizer и на основе TfidfVectorizer.\n",
    "\n",
    "В качестве классификаторов необходимо использовать два классификатора по варианту для Вашей группы: RandomForestClassifier, Complement Naive Bayes (CNB)\n",
    "\n",
    "Для каждого метода необходимо оценить качество классификации. Сделайте вывод о том, какой вариант векторизации признаков в паре с каким классификатором показал лучшее качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-25T16:43:58.766019Z",
     "iopub.status.busy": "2021-05-25T16:43:58.765477Z",
     "iopub.status.idle": "2021-05-25T16:44:00.305026Z",
     "shell.execute_reply": "2021-05-25T16:44:00.303954Z",
     "shell.execute_reply.started": "2021-05-25T16:43:58.765900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amazon-fine-food-reviews/hashes.txt\n",
      "/kaggle/input/amazon-fine-food-reviews/Reviews.csv\n",
      "/kaggle/input/amazon-fine-food-reviews/database.sqlite\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC, OneClassSVM, SVR, NuSVR, LinearSVR\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T16:44:02.276366Z",
     "iopub.status.busy": "2021-05-25T16:44:02.275958Z",
     "iopub.status.idle": "2021-05-25T16:44:02.286740Z",
     "shell.execute_reply": "2021-05-25T16:44:02.285547Z",
     "shell.execute_reply.started": "2021-05-25T16:44:02.276334Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T16:44:58.729876Z",
     "iopub.status.busy": "2021-05-25T16:44:58.729419Z",
     "iopub.status.idle": "2021-05-25T16:45:08.003685Z",
     "shell.execute_reply": "2021-05-25T16:45:08.002728Z",
     "shell.execute_reply.started": "2021-05-25T16:44:58.729835Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/amazon-fine-food-reviews/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T16:45:08.006960Z",
     "iopub.status.busy": "2021-05-25T16:45:08.006454Z",
     "iopub.status.idle": "2021-05-25T16:45:08.012148Z",
     "shell.execute_reply": "2021-05-25T16:45:08.011282Z",
     "shell.execute_reply.started": "2021-05-25T16:45:08.006897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T16:45:08.014199Z",
     "iopub.status.busy": "2021-05-25T16:45:08.013726Z",
     "iopub.status.idle": "2021-05-25T16:45:08.055165Z",
     "shell.execute_reply": "2021-05-25T16:45:08.053983Z",
     "shell.execute_reply.started": "2021-05-25T16:45:08.014166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T16:45:30.419725Z",
     "iopub.status.busy": "2021-05-25T16:45:30.419288Z",
     "iopub.status.idle": "2021-05-25T16:45:30.440386Z",
     "shell.execute_reply": "2021-05-25T16:45:30.438945Z",
     "shell.execute_reply.started": "2021-05-25T16:45:30.419683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    363122\n",
       "4     80655\n",
       "1     52268\n",
       "3     42640\n",
       "2     29769\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T17:03:41.189660Z",
     "iopub.status.busy": "2021-05-25T17:03:41.189227Z",
     "iopub.status.idle": "2021-05-25T17:03:41.201301Z",
     "shell.execute_reply": "2021-05-25T17:03:41.200174Z",
     "shell.execute_reply.started": "2021-05-25T17:03:41.189619Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def test(word):\n",
    "    if word.isalpha() and len(word) > 2 and word.lower() not in stop:\n",
    "        s=(sno.stem(word.lower()))\n",
    "        return s\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#initialising the snowball stemmer\n",
    "sno = nltk.stem.SnowballStemmer('english')    \n",
    "def preprocess_sentence(w):\n",
    "    w = re.sub('\\t\\n', '', w)\n",
    "    w = re.sub(r'http\\S+', '', w)\n",
    "    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,`']+\", \" \", w)\n",
    "\n",
    "    w = w.strip().split()\n",
    "    text = [test(x) for x in w if test(x)]\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T17:03:42.457502Z",
     "iopub.status.busy": "2021-05-25T17:03:42.457064Z",
     "iopub.status.idle": "2021-05-25T17:18:27.809922Z",
     "shell.execute_reply": "2021-05-25T17:18:27.808739Z",
     "shell.execute_reply.started": "2021-05-25T17:03:42.457464Z"
    }
   },
   "outputs": [],
   "source": [
    "train.Text = train.Text.apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T17:26:49.460293Z",
     "iopub.status.busy": "2021-05-25T17:26:49.459839Z",
     "iopub.status.idle": "2021-05-25T17:27:23.620487Z",
     "shell.execute_reply": "2021-05-25T17:27:23.619298Z",
     "shell.execute_reply.started": "2021-05-25T17:26:49.460258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество сформированных признаков - 73376\n"
     ]
    }
   ],
   "source": [
    "vocabVect = CountVectorizer()\n",
    "vocabVect.fit(train.Text)\n",
    "corpusVocab = vocabVect.vocabulary_\n",
    "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T16:48:58.779645Z",
     "iopub.status.busy": "2021-05-25T16:48:58.779194Z",
     "iopub.status.idle": "2021-05-25T16:48:58.791370Z",
     "shell.execute_reply": "2021-05-25T16:48:58.790203Z",
     "shell.execute_reply.started": "2021-05-25T16:48:58.779609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought=10722\n",
      "several=83580\n",
      "of=64753\n",
      "the=94178\n",
      "vitality=101486\n",
      "canned=13501\n",
      "dog=27448\n",
      "food=35881\n",
      "products=73379\n"
     ]
    }
   ],
   "source": [
    "for i in list(corpusVocab)[1:10]:\n",
    "    print('{}={}'.format(i, corpusVocab[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T16:49:08.801172Z",
     "iopub.status.busy": "2021-05-25T16:49:08.800762Z",
     "iopub.status.idle": "2021-05-25T16:55:27.977594Z",
     "shell.execute_reply": "2021-05-25T16:55:27.976434Z",
     "shell.execute_reply.started": "2021-05-25T16:49:08.801140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<568454x14619665 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 112480629 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfv = TfidfVectorizer(ngram_range=(1,3))\n",
    "tfidf_ngram_features = tfidfv.fit_transform(train.Text)\n",
    "tfidf_ngram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T16:56:57.184773Z",
     "iopub.status.busy": "2021-05-25T16:56:57.183789Z",
     "iopub.status.idle": "2021-05-25T16:56:57.198319Z",
     "shell.execute_reply": "2021-05-25T16:56:57.196790Z",
     "shell.execute_reply.started": "2021-05-25T16:56:57.184684Z"
    }
   },
   "outputs": [],
   "source": [
    "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
    "    for v in vectorizers_list:\n",
    "        for c in classifiers_list:\n",
    "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
    "            score = cross_val_score(pipeline1, train.Text[:10000], train.Score[:10000], scoring='accuracy', cv=3,).mean()\n",
    "            print('Векторизация - {}'.format(v))\n",
    "            print('Модель для классификации - {}'.format(c))\n",
    "            print('Accuracy = {}'.format(score))\n",
    "            print('===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T17:27:48.657961Z",
     "iopub.status.busy": "2021-05-25T17:27:48.657544Z",
     "iopub.status.idle": "2021-05-25T17:30:47.362276Z",
     "shell.execute_reply": "2021-05-25T17:30:47.360940Z",
     "shell.execute_reply.started": "2021-05-25T17:27:48.657925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaa': 2, 'aaaaa': 3,\n",
      "                            'aaaaaa': 4, 'aaaaaaaaaa': 5, 'aaaaaaaaaaa': 6,\n",
      "                            'aaaaaaaaaaaa': 7, 'aaaaaaaaaaaaa': 8,\n",
      "                            'aaaaaaaaaaaaaa': 9, 'aaaaaaaaaaaaaaa': 10,\n",
      "                            'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa': 11,\n",
      "                            'aaaaaaaaaaaaaaaaaaaargh': 12,\n",
      "                            'aaaaaaaaaaaaaaaaacccccccckkkkkk': 13,\n",
      "                            'aaaaaaaaagghh': 14, 'aaaaaaah': 15,\n",
      "                            'aaaaaaahhhhhh': 16, 'aaaaaaarrrrrggghhh': 17,\n",
      "                            'aaaaaah': 18, 'aaaaaahhh': 19, 'aaaaaahhhh': 20,\n",
      "                            'aaaaaahhhhh': 21, 'aaaaaahhhhhyaaaaaa': 22,\n",
      "                            'aaaaaand': 23, 'aaaaaawwwwwwwwww': 24,\n",
      "                            'aaaaah': 25, 'aaaaahhhhhhhhhhhhhhhh': 26,\n",
      "                            'aaaaallll': 27, 'aaaaawsom': 28, 'aaaah': 29, ...})\n",
      "Модель для классификации - RandomForestClassifier()\n",
      "Accuracy = 0.6243000724787536\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaa': 2, 'aaaaa': 3,\n",
      "                            'aaaaaa': 4, 'aaaaaaaaaa': 5, 'aaaaaaaaaaa': 6,\n",
      "                            'aaaaaaaaaaaa': 7, 'aaaaaaaaaaaaa': 8,\n",
      "                            'aaaaaaaaaaaaaa': 9, 'aaaaaaaaaaaaaaa': 10,\n",
      "                            'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa': 11,\n",
      "                            'aaaaaaaaaaaaaaaaaaaargh': 12,\n",
      "                            'aaaaaaaaaaaaaaaaacccccccckkkkkk': 13,\n",
      "                            'aaaaaaaaagghh': 14, 'aaaaaaah': 15,\n",
      "                            'aaaaaaahhhhhh': 16, 'aaaaaaarrrrrggghhh': 17,\n",
      "                            'aaaaaah': 18, 'aaaaaahhh': 19, 'aaaaaahhhh': 20,\n",
      "                            'aaaaaahhhhh': 21, 'aaaaaahhhhhyaaaaaa': 22,\n",
      "                            'aaaaaand': 23, 'aaaaaawwwwwwwwww': 24,\n",
      "                            'aaaaah': 25, 'aaaaahhhhhhhhhhhhhhhh': 26,\n",
      "                            'aaaaallll': 27, 'aaaaawsom': 28, 'aaaah': 29, ...})\n",
      "Модель для классификации - ComplementNB()\n",
      "Accuracy = 0.6250998525167454\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaa': 2, 'aaaaa': 3,\n",
      "                            'aaaaaa': 4, 'aaaaaaaaaa': 5, 'aaaaaaaaaaa': 6,\n",
      "                            'aaaaaaaaaaaa': 7, 'aaaaaaaaaaaaa': 8,\n",
      "                            'aaaaaaaaaaaaaa': 9, 'aaaaaaaaaaaaaaa': 10,\n",
      "                            'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa': 11,\n",
      "                            'aaaaaaaaaaaaaaaaaaaargh': 12,\n",
      "                            'aaaaaaaaaaaaaaaaacccccccckkkkkk': 13,\n",
      "                            'aaaaaaaaagghh': 14, 'aaaaaaah': 15,\n",
      "                            'aaaaaaahhhhhh': 16, 'aaaaaaarrrrrggghhh': 17,\n",
      "                            'aaaaaah': 18, 'aaaaaahhh': 19, 'aaaaaahhhh': 20,\n",
      "                            'aaaaaahhhhh': 21, 'aaaaaahhhhhyaaaaaa': 22,\n",
      "                            'aaaaaand': 23, 'aaaaaawwwwwwwwww': 24,\n",
      "                            'aaaaah': 25, 'aaaaahhhhhhhhhhhhhhhh': 26,\n",
      "                            'aaaaallll': 27, 'aaaaawsom': 28, 'aaaah': 29, ...})\n",
      "Модель для классификации - RandomForestClassifier()\n",
      "Accuracy = 0.6224999224577527\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'aa': 0, 'aaa': 1, 'aaaa': 2, 'aaaaa': 3,\n",
      "                            'aaaaaa': 4, 'aaaaaaaaaa': 5, 'aaaaaaaaaaa': 6,\n",
      "                            'aaaaaaaaaaaa': 7, 'aaaaaaaaaaaaa': 8,\n",
      "                            'aaaaaaaaaaaaaa': 9, 'aaaaaaaaaaaaaaa': 10,\n",
      "                            'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa': 11,\n",
      "                            'aaaaaaaaaaaaaaaaaaaargh': 12,\n",
      "                            'aaaaaaaaaaaaaaaaacccccccckkkkkk': 13,\n",
      "                            'aaaaaaaaagghh': 14, 'aaaaaaah': 15,\n",
      "                            'aaaaaaahhhhhh': 16, 'aaaaaaarrrrrggghhh': 17,\n",
      "                            'aaaaaah': 18, 'aaaaaahhh': 19, 'aaaaaahhhh': 20,\n",
      "                            'aaaaaahhhhh': 21, 'aaaaaahhhhhyaaaaaa': 22,\n",
      "                            'aaaaaand': 23, 'aaaaaawwwwwwwwww': 24,\n",
      "                            'aaaaah': 25, 'aaaaahhhhhhhhhhhhhhhh': 26,\n",
      "                            'aaaaallll': 27, 'aaaaawsom': 28, 'aaaah': 29, ...})\n",
      "Модель для классификации - ComplementNB()\n",
      "Accuracy = 0.6182000023637636\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n",
    "classifiers_list = [RandomForestClassifier(), ComplementNB()]\n",
    "VectorizeAndClassify(vectorizers_list, classifiers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лучший результат показала модель ComplementNB с CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
